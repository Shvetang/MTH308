{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9deb62ed",
   "metadata": {},
   "source": [
    "# Iterative Methods for Solving Linear Systems\n",
    "\n",
    "We are solving the following system of linear equations:\n",
    "\n",
    "\\begin{aligned}\n",
    "5x_1 - 2x_2 + 3x_3 &= -1 \\\\\n",
    "-3x_1 + 9x_2 + x_3 &= 2 \\\\\n",
    "2x_1 - x_2 - 7x_3 &= 3\n",
    "\\end{aligned}\n",
    "\n",
    "The basic procedure is to start with an initial guess for the solution and repeatedly refine it by using the given equations to find the next values of the variables. The process is repeated until the solution is accurate enough.\n",
    "\n",
    "## Initial Guess\n",
    "\n",
    "We start with the initial guess:$\\quad x_1^{(0)} = 0,\\quad x_2^{(0)} = 0,\\quad x_3^{(0)} = 0$\n",
    "\n",
    "---\n",
    "\n",
    "## Gauss-Jacobi Method\n",
    "\n",
    "In the Jacobi method, we compute each new value using only the values from the **previous iteration**.\n",
    "\n",
    "Update formulas:\n",
    "\n",
    "\\begin{aligned}\n",
    "x_1^{(k+1)} &= \\frac{1}{5} \\left( -1 + 2x_2^{(k)} - 3x_3^{(k)} \\right) \\\\\n",
    "x_2^{(k+1)} &= \\frac{1}{9} \\left( 2 + 3x_1^{(k)} - x_3^{(k)} \\right) \\\\\n",
    "x_3^{(k+1)} &= \\frac{1}{-7} \\left( 3 - 2x_1^{(k)} + x_2^{(k)} \\right)\n",
    "\\end{aligned}\n",
    "\n",
    "## Gauss-Seidel Method\n",
    "\n",
    "In the Gauss-Seidel method, we update values **in-place**, using the latest computed values within the same iteration.\n",
    "\n",
    "Update formulas:\n",
    "\\begin{aligned}\n",
    "x_1^{(k+1)} &= \\frac{1}{5} \\left( -1 + 2x_2^{(k)} - 3x_3^{(k)} \\right) \\\\\n",
    "x_2^{(k+1)} &= \\frac{1}{9} \\left( 2 + 3x_1^{(k+1)} - x_3^{(k)} \\right) \\\\\n",
    "x_3^{(k+1)} &= \\frac{1}{-7} \\left( 3 - 2x_1^{(k+1)} + x_2^{(k+1)} \\right)\n",
    "\\end{aligned}\n",
    "\n",
    "## Successive Over-Relaxation (SOR) Method\n",
    "\n",
    "SOR is a modification of Gauss-Seidel that introduces a **relaxation parameter** $\\omega$, $1 < \\omega < 2$. The goal is to accelerate convergence.\n",
    "\n",
    "Update formulas:\n",
    "\n",
    "\\begin{aligned}\n",
    "x_1^{(k+1)} &= (1 - \\omega)x_1^{(k)} + \\frac{\\omega}{5} \\left( -1 + 2x_2^{(k)} - 3x_3^{(k)} \\right) \\\\\n",
    "x_2^{(k+1)} &= (1 - \\omega)x_2^{(k)} + \\frac{\\omega}{9} \\left( 2 + 3x_1^{(k+1)} - x_3^{(k)} \\right) \\\\\n",
    "x_3^{(k+1)} &= (1 - \\omega)x_3^{(k)} + \\frac{\\omega}{-7} \\left( 3 - 2x_1^{(k+1)} + x_2^{(k+1)} \\right)\n",
    "\\end{aligned}\n",
    "\n",
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "- Gauss-Seidel generally converges faster than Gauss-Jacobi.\n",
    "- SOR can outperform both if $\\omega$ is chosen well.\n",
    "- All methods assume the matrix is diagonally dominant or suitable for convergence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7e8c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "Solving the system of equations:\n",
    "5x - 2y +3z = -1\n",
    "-3x + 9y + z = 2\n",
    "2x - y - 7z = 3\n",
    "'''\n",
    "\n",
    "# Define coefficient matrix and RHS\n",
    "A = np.array([\n",
    "    [5, -2, 3],\n",
    "    [-3, 9, 1],\n",
    "    [2, -1, -7]\n",
    "], dtype=float)\n",
    "\n",
    "b = np.array([-1, 2, 3], dtype=float)\n",
    "\n",
    "# Define initial value\n",
    "x_init = np.array([0, 0, 0], dtype=float)         # initial guess x_0 = [0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b60be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_jacobi(x_init, A, b, iterations=10):\n",
    "    n = len(b)\n",
    "    x = x_init\n",
    "    history = []\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        x_new = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            s = sum(A[i][j] * x[j] for j in range(n) if j != i)\n",
    "            x_new[i] = (b[i] - s) / A[i][i]\n",
    "        diff = np.abs(x_new - x)\n",
    "        history.append(np.concatenate((x_new, diff)))\n",
    "        x = x_new\n",
    "    cols = [\"x1 (J)\", \"x2 (J)\", \"x3 (J)\", \"Δx1 (J)\", \"Δx2 (J)\", \"Δx3 (J)\"]\n",
    "    return pd.DataFrame(history, columns=cols)\n",
    "\n",
    "def gauss_seidel(x_init, A, b, iterations=10):\n",
    "    n = len(b)\n",
    "    x = x_init\n",
    "    history = []\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        x_new = x.copy()\n",
    "        for i in range(n):\n",
    "            s1 = sum(A[i][j] * x_new[j] for j in range(i))\n",
    "            s2 = sum(A[i][j] * x[j] for j in range(i + 1, n))\n",
    "            x_new[i] = (b[i] - s1 - s2) / A[i][i]\n",
    "        diff = np.abs(x_new - x)\n",
    "        history.append(np.concatenate((x_new, diff)))\n",
    "        x = x_new\n",
    "    cols = [\"x1 (S)\", \"x2 (S)\", \"x3 (S)\", \"Δx1 (S)\", \"Δx2 (S)\", \"Δx3 (S)\"]\n",
    "    return pd.DataFrame(history, columns=cols)\n",
    "\n",
    "def sor_method(x_init, A, b, w=1.25, iterations=10):     # default w = 1.25\n",
    "    n = len(b)\n",
    "    x = x_init\n",
    "    history = []\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        x_new = x.copy()\n",
    "        for i in range(n):\n",
    "            s1 = sum(A[i][j] * x_new[j] for j in range(i))       # updated\n",
    "            s2 = sum(A[i][j] * x[j] for j in range(i + 1, n))     # previous\n",
    "            x_new[i] = (1 - w) * x[i] + w * (b[i] - s1 - s2) / A[i][i]\n",
    "        diff = np.abs(x_new - x)\n",
    "        history.append(np.concatenate((x_new, diff)))\n",
    "        x = x_new\n",
    "    cols = [\"x1 (SOR)\", \"x2 (SOR)\", \"x3 (SOR)\", \"Δx1 (SOR)\", \"Δx2 (SOR)\", \"Δx3 (SOR)\"]\n",
    "    return pd.DataFrame(history, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10f80ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Gauss-Jacobi method: \n",
      "     x1 (J)    x2 (J)    x3 (J)   Δx1 (J)   Δx2 (J)   Δx3 (J)\n",
      "0 -0.200000  0.222222 -0.428571  0.200000  0.222222  0.428571\n",
      "1  0.146032  0.203175 -0.517460  0.346032  0.019048  0.088889\n",
      "2  0.191746  0.328395 -0.415873  0.045714  0.125220  0.101587\n",
      "3  0.180882  0.332346 -0.420700  0.010864  0.003951  0.004827\n",
      "4  0.185359  0.329261 -0.424369  0.004477  0.003085  0.003668\n",
      "5  0.186326  0.331160 -0.422649  0.000967  0.001900  0.001720\n",
      "6  0.186054  0.331292 -0.422644  0.000272  0.000131  0.000005\n",
      "7  0.186103  0.331201 -0.422741  0.000050  0.000091  0.000096\n",
      "8  0.186125  0.331228 -0.422713  0.000021  0.000027  0.000027\n",
      "9  0.186119  0.331232 -0.422711  0.000005  0.000004  0.000002\n",
      "\n",
      "Result of Gauss-Seidel method: \n",
      "     x1 (S)    x2 (S)    x3 (S)       Δx1 (S)       Δx2 (S)       Δx3 (S)\n",
      "0 -0.200000  0.155556 -0.507937  2.000000e-01  1.555556e-01  5.079365e-01\n",
      "1  0.166984  0.334321 -0.428622  3.669841e-01  1.787654e-01  7.931469e-02\n",
      "2  0.190901  0.333481 -0.421668  2.391736e-02  8.402900e-04  6.953573e-03\n",
      "3  0.186393  0.331205 -0.422631  4.508260e-03  2.275372e-03  9.630210e-04\n",
      "4  0.186061  0.331202 -0.422726  3.323364e-04  3.776459e-06  9.441376e-05\n",
      "5  0.186116  0.331230 -0.422714  5.513767e-05  2.886964e-05  1.162939e-05\n",
      "6  0.186121  0.331231 -0.422713  4.570225e-06  2.312543e-07  1.272742e-06\n",
      "7  0.186120  0.331230 -0.422713  6.711436e-07  3.651303e-07  1.395938e-07\n",
      "8  0.186120  0.331230 -0.422713  6.229583e-08  5.254851e-09  1.704812e-08\n",
      "9  0.186120  0.331230 -0.422713  8.126929e-09  4.603211e-09  1.664378e-09\n",
      "\n",
      "Result of SOR method: \n",
      "   x1 (SOR)  x2 (SOR)  x3 (SOR)  Δx1 (SOR)  Δx2 (SOR)  Δx3 (SOR)\n",
      "0 -0.250000  0.173611 -0.656002   0.250000   0.173611   0.656002\n",
      "1  0.391307  0.488531 -0.319199   0.641307   0.314920   0.336803\n",
      "2  0.135838  0.256577 -0.453218   0.255469   0.231954   0.134019\n",
      "3  0.184243  0.353348 -0.419707   0.048405   0.096771   0.033512\n",
      "4  0.195393  0.329147 -0.419781   0.011150   0.024201   0.000074\n",
      "5  0.180561  0.329027 -0.425038   0.014833   0.000120   0.005257\n",
      "6  0.188152  0.332951 -0.421713   0.007591   0.003923   0.003325\n",
      "7  0.185722  0.330496 -0.422974   0.002430   0.002455   0.001261\n",
      "8  0.186048  0.331420 -0.422707   0.000325   0.000924   0.000266\n",
      "9  0.186229  0.331227 -0.422675   0.000181   0.000193   0.000033\n",
      "\n",
      "True solution:\n",
      " [ 0.18611987  0.33123028 -0.42271293]\n"
     ]
    }
   ],
   "source": [
    "jacobi_df = gauss_jacobi(x_init, A, b)\n",
    "print(\"Result of Gauss-Jacobi method: \")\n",
    "print(jacobi_df)\n",
    "\n",
    "seidel_df = gauss_seidel(x_init, A, b)\n",
    "print(\"\\nResult of Gauss-Seidel method: \")\n",
    "print(seidel_df)\n",
    "\n",
    "sor_df = sor_method(x_init, A, b)\n",
    "print(\"\\nResult of SOR method: \")\n",
    "print(sor_df)\n",
    "\n",
    "# True solution for reference\n",
    "x_true = np.linalg.solve(A, b)\n",
    "print(\"\\nTrue solution:\\n\", x_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba0c151",
   "metadata": {},
   "source": [
    "### Comparison of Results\n",
    "As can be seen, both methods give good results after 10 iterations. However, there are some key differences:  \n",
    "- The Gauss-Seidel method converges faster (almost 2X) than the Jacobi method. This is because the Gauss-Seidel method uses the latest values of the variables immediately, whereas the Jacobi method uses the old values.\n",
    "- The Gauss-Jacobi method has the advantage of being highly parallelizable.\n",
    "- The SOR method is faster than both the Gauss-Seidel and Jacobi methods. However, it requires a parameter ($\\omega$) that needs to be chosen carefully. If $\\omega$ is too small, the method converges slowly, and if it is too large, the method may not converge at all. Finding the best fit $\\omega$ is not an easy task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
